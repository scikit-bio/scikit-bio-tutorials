{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5cfaOQykOA3r"
   },
   "source": [
    "# Embeddings and Vectors with Scikit-Bio\n",
    "\n",
    "**Welcome to scikit-bio tutorial-02!** In this tutorial, we will showcase how the scikit-bio library can be utilized for embedding and vectorizing sets of protein sequences. Our goal is to demonstrate sequence classification and structural alignment using *TM-Vec* and *DeepBLAST* respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQnrfNbnOA3u"
   },
   "source": [
    "### Introduction - a role of deep learning in `scikit-bio`\n",
    "he application of deep learning in biology is gaining widespread popularity, with protein language models (pLMs) being a notable success story. By generating protein embeddings from sequence data, pLMs have paved the way for a range of innovative applications, including, for instance, fluorescent protein design by [ESM3](https://techcrunch.com/2024/06/25/evolutionaryscale-backed-by-amazon-and-nvidia-raises-142m-for-protein-generating-ai/) and [CRISPR-Cas design](https://www.biorxiv.org/content/10.1101/2024.04.22.590591v1).\n",
    "\n",
    "Compared to traditional letter-encoded amino acids, protein embeddings offer a more expressive representation of a protein. In addition to sequence information, they encode structural, evolutionary (including organism of origin), and functional (such as thermostability and fluorescence) properties. These embeddings can be viewed as a compressed representation of multiple sequence alignments (MSAs), and thus, any task that benefits from MSA will also benefit from operations on embeddings. As computational optimizations of protein language models (pLMs) continue to emerge, embeddings-based methods are likely to gain popularity. Our goal is to provide an infrastructure that enables users to conduct sequence analysis leveraging embeddings.\n",
    "\n",
    "However, not all tasks benefit from embeddings. The limitations of embeddings are discussed in detail in [Li et al., 2024](https://www.biorxiv.org/content/10.1101/2024.02.05.578959v2.abstract)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Nf-rJkLOA3w"
   },
   "source": [
    "### What is TM-Vec?\n",
    "[TM-Vec](https://www.nature.com/articles/s41587-023-01917-2) is a tool that utilises protein representations from pLM in order to predict structural similarity of two proteins.\n",
    "### How does TM-Vec work?\n",
    "General protein representations (also called \"embeddings\"), that are predictive of protein structure, are obtained from pLM (ProtT5). Next, they are modified into vectors with the help of TM-Vec, which is another neural network. TM-Vec encodes proteins in a way that allows the cosine distance between two vectors to approximate structural similarity (measure via TM-score), thereby eliminating the need for time-consuming structure prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MSwJVIAcOA3x"
   },
   "outputs": [],
   "source": [
    "from importlib.util import find_spec\n",
    "if find_spec('skbio') is None:\n",
    "    !pip install -q scikit-bio\n",
    "\n",
    "if find_spec('tmvec') is None:\n",
    "    !pip install -q git+https://github.com/valentynbez/tmvec.git\n",
    "\n",
    "if find_spec('deepblast') is None:\n",
    "    !pip install -q git+https://github.com/valentynbez/deepblast.git\n",
    "\n",
    "if find_spec('onnx') is None:\n",
    "    !pip install -q onnx\n",
    "\n",
    "!pip install -q biopython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "5DV1eSXoOA30",
    "outputId": "b4f0c4d1-e03d-440c-f57c-b58ad5d620c7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'0.6.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import skbio\n",
    "skbio.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qb0D5YFqOA32",
    "outputId": "2b556d36-dbb6-43a7-808b-a86b50942a1a"
   },
   "outputs": [],
   "source": [
    "# get data\n",
    "!mkdir data\n",
    "!wget -q -O ./data/pdb_hits.fa \"https://raw.githubusercontent.com/scikit-bio/scikit-bio-tutorials/main/02-language-model/data/pdb_hits.fa\"\n",
    "!wget -q -O ./data/bacteriocin.csv \"https://raw.githubusercontent.com/scikit-bio/scikit-bio-tutorials/main/02-language-model/data/bagel_bacteriocins_all_classes.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RHZWhs4lOA33"
   },
   "outputs": [],
   "source": [
    "# All Necessary imports\n",
    "from deepblast.dataset.utils import get_sequence, pack_sequences, revstate_f, states2alignment\n",
    "from deepblast.utils import load_model\n",
    "from skbio.embedding import ProteinEmbedding, ProteinVector\n",
    "from tmvec.embedding import ProtT5Encoder\n",
    "from skbio.alignment import TabularMSA\n",
    "from skbio.sequence import Protein\n",
    "import matplotlib.pyplot as plt\n",
    "import skbio.embedding as emb\n",
    "from skbio.io import read\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Vz5B2XHOA33"
   },
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "UewAqLbTOA33"
   },
   "outputs": [],
   "source": [
    "# Helper Functions for Embedding Sequences\n",
    "def load_protein_t5_embedding(sequence, model_path, tokenizer_path):\n",
    "\n",
    "    embedder = ProtT5Encoder(model_path=model_path, tokenizer_path=tokenizer_path, backend=\"onnx\")\n",
    "\n",
    "    # generate embeddings\n",
    "    emb = embedder.get_sequence_embeddings([sequence])[0]\n",
    "\n",
    "    return ProteinEmbedding(emb, sequence)\n",
    "\n",
    "\n",
    "def to_embeddings(sequences : list, model_name, tokenizer_name):\n",
    "    # Embed the random/inputted protein sequence(s)\n",
    "    for sequence in tqdm(sequences):\n",
    "        test_embed = load_protein_t5_embedding(str(sequence), model_name, tokenizer_name)\n",
    "        #reshape embeddings to fit the skbio format\n",
    "        yield test_embed\n",
    "\n",
    "def align(x, y, model):\n",
    "    pred_alignment = model.align(str(x), str(y))\n",
    "    return pred_alignment\n",
    "\n",
    "\n",
    "def predict_aln_matrix(query_seq, target_seq, model):\n",
    "    x_code = get_sequence(str(query_seq), model.tokenizer)[0].to(model.device)\n",
    "    y_code = get_sequence(str(target_seq), model.tokenizer)[0].to(model.device)\n",
    "    seq, order = pack_sequences([x_code], [y_code])\n",
    "    with torch.no_grad():\n",
    "        gen = model.aligner.traceback(seq, order)\n",
    "    _, aln_mat = next(gen)\n",
    "\n",
    "    return aln_mat.squeeze().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "sGg4C7PqOA34"
   },
   "outputs": [],
   "source": [
    "# Load_vector function for vectors\n",
    "def load_vectors(file_path, sequence_list : list):\n",
    "      data = np.load(file_path, allow_pickle=True)\n",
    "      vectors = data['embeddings']\n",
    "\n",
    "      protein_vectors = [ProteinVector(vector, sequence) for vector, sequence in zip(vectors, sequence_list)]\n",
    "      return protein_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJaGOMm6OA34"
   },
   "source": [
    "### Part 1: Embedding sequences to file\n",
    "\n",
    "We're going to start by reading in the bacteriocin sequences with `skbio.read`, then storing the embedded sequences in `ProteinEmbedding` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "GJwkZ5LXOA34"
   },
   "outputs": [],
   "source": [
    "# a model we prepared for a faster execution on CPU\n",
    "model_path = \"scikit-bio/prot-t5-xl-uniref50-onnx\"\n",
    "# tokenizer from standard repo\n",
    "tokenizer_path = \"Rostlab/prot_t5_xl_uniref50\"\n",
    "\n",
    "# Parse bagel.fa\n",
    "sequence_list = read(\"data/pdb_hits.fa\", format='fasta')\n",
    "embed_list = to_embeddings(sequence_list, model_path, tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LCMb2horOA35",
    "outputId": "0b13247e-e974-45df-d67c-e650275ee891"
   },
   "outputs": [],
   "source": [
    "next(embed_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SaRa-sufOA35"
   },
   "source": [
    "### Part 2: Building vector-DB and plot Ordination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mwFP_HunOA35"
   },
   "source": [
    "We can directly feed our FASTA file into the tmvec build_db __CLI__ function, which will output our\n",
    "vectors as a .npz file in the specified directory.\n",
    "\n",
    "This function takes in as an input:\n",
    "1. --input-fasta: A FASTA file containing your sequences.\n",
    "2. --output: the file location to output to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hr2nK-TCOA35",
    "outputId": "ab4009de-2ec9-433c-b812-35398ee3443f"
   },
   "outputs": [],
   "source": [
    "!tmvec build-db --input-fasta data/pdb_hits.fa --output outputs/pdb_hits_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KsFE_IffOA36"
   },
   "source": [
    "With the proteins encoded as vectors within a database, we can extract the vectors and\n",
    "cast them to ProteinVectors objects, which can then be used to visualize the structural similarity between the proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "PQZinb1qOA36",
    "outputId": "7ed0f600-9061-431e-d46d-c275d2f546aa"
   },
   "outputs": [],
   "source": [
    "# load sequences\n",
    "sequence_list = read(\"data/pdb_hits.fa\", format='fasta')\n",
    "\n",
    "#read in vectors to generator object\n",
    "vec_generator = load_vectors(\"outputs/pdb_hits_output.npz\", sequence_list)\n",
    "\n",
    "# convert the vectors into an OrdinationResults object for plotting\n",
    "ord_results = emb.embed_vec_to_ordination(vec_generator)\n",
    "\n",
    "# read in the bacterion sequence / function metadata\n",
    "df = pd.read_csv(\"data/bacteriocin.csv\")\n",
    "df = df.dropna(subset=['Sequence']).set_index('Sequence')\n",
    "df = df.groupby('Sequence').first()\n",
    "# match the sequence ids to the rows in the metadata\n",
    "common_ids = list(set(ord_results.samples.index) & set(df.index))\n",
    "\n",
    "df = df.loc[common_ids]\n",
    "\n",
    "ord_results.samples = ord_results.samples.loc[common_ids]\n",
    "\n",
    "# plot the results\n",
    "ord_results.plot(df, column='class', title='Bacteriocin Sequence TM-Scores');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VYltrbiQk2Ih"
   },
   "outputs": [],
   "source": [
    "del(to_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7gEvlBVOA37"
   },
   "source": [
    "### Part 3: Structural Alignment with DeepBLAST\n",
    "\n",
    "DeepBLAST is a deep learning tool that leverages protein embeddings to incorporate structural alignment information into sequence alignment. In essence, DeepBLAST has distilled information from thousands of observed protein structure alignments and integrated it into its alignment matrix. Consequently, DeepBLAST alignments can accurately match dissimilar amino acids based on structural information, making it the most accurate sequence-based method in the [Malidup and Malisam benchmarks](https://www.nature.com/articles/s41587-023-01917-2/tables/2). hile it falls short of structure alignment methods in terms of accuracy, DeepBLAST significantly reduces computational requirements, rendering the analysis of large datasets more feasible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pHU8S7pvOA37",
    "outputId": "fb1074ad-df04-4f71-e60f-0b73d739e4b5"
   },
   "outputs": [],
   "source": [
    "# download the model from scikit-bio HuggingFace repository!\n",
    "!wget https://huggingface.co/scikit-bio/deepblast/resolve/main/deepblast-v3.ckpt -O ./data/deepblast-v3.ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "0D8DGt1cOA37"
   },
   "outputs": [],
   "source": [
    "bagel_list = read(\"data/pdb_hits.fa\", format='fasta', constructor=Protein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "005TS67fOA37"
   },
   "outputs": [],
   "source": [
    "x = next(bagel_list)\n",
    "y = next(bagel_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "52zuGvCYOA38",
    "outputId": "1ecfdfb9-e7c8-4df7-d9a3-4b286ed012de"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"./data/deepblast-v3.ckpt\", device=\"cpu\",\n",
    "                   alignment_mode=\"needleman-wunsch\"\n",
    "                   )\n",
    "\n",
    "path = align(x, y, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "R8Z1BNLjjaq0"
   },
   "outputs": [],
   "source": [
    "x_aligned, y_aligned = states2alignment(path, str(x), str(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J16abiGfmtkn",
    "outputId": "d8cc4243-95ed-4fe3-c429-01fedd3978c4"
   },
   "outputs": [],
   "source": [
    "print(x_aligned)\n",
    "print(y_aligned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7t3vYltOA38"
   },
   "source": [
    "### Part 4: Visualization of Predicted Alignment Matrix\n",
    "\n",
    "Probabilities and regions of alignment between two sequences can be visualized, thus enabling detailed analysis of conserved regions of proteins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "id": "FeebNj1KOA38",
    "outputId": "1984cf17-6082-456a-b3f8-2055a7bd887e"
   },
   "outputs": [],
   "source": [
    "matrix = predict_aln_matrix(x, y, model)\n",
    "\n",
    "# visualise matrix with cbar\n",
    "plt.imshow(matrix, cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
